- might change

rendering
	prepass
		depth only prepass for everything other than shadowmaps
		draw opaque, alpha tested particles to depth buffer in the depth prepass as well as draw them first.

	world
		Split up into grid sections
		each grid with its own VAO and VBO
		when "adding" a model, the vbo is updated for that
		when removing a model, the VBO is either completely regenerated or redone
		perhaps have something like a "bake" function
	entity
		each entity has a "model" and perhaps a animation
		animations transformations are stored in buffers in the gpu
		only have to pass a framenumber to the shader, it gpu skins based on that.
		for ragdolls, would need to transfer them to the gpu.
		likely too different to have gain from instancing
		seperate out if they have transparency in their textures
	shaders 
		have each shader, but also have a permutation generator
		only generates the permutations if something in the scene calls for it.
	water/reflections
		todo
	lighting
		frustrum culled by its max sphere
		x max shadowmaps
		shadowmaps are shuffled around to nearest lights in view
		possibly deferred w/shadows
		shadowmaps
		possibly pssm for sun shadow
	particles
		draw opaque, alpha tested particles to depth buffer in the depth prepass as well as draw them first.
		current basic particle physics- can be done on gpu if needed (i've done it on gpu)
		soft particles - easy, i've done it before
		sorting may be possible on gpu
		Particle system style.
		sort systems, sort particles in each system.
		perhaps OpenGL3.3 geo shaders for some of the particle billboarding.
			(max throughput of 5 floats per particle, not 12 like manually pushing verts)
			(also no 6 ints for the indices, geo shader does that)
	framebuffers
	viewports - needed for shadows, env maps, reflections, cameras, etc
	textures
		texturegroups
			list of 5 or so textures for the same model/surface
			
	lod
		lod switching cpu side
		all lod stages of model loaded into gpu
		lod depends on fov and distance
	culling
		cull lights by bounding box/sphere/cone
		view culling entities - bounding box completely outside of viewport
		view culling
		depth prepass
		draw opaque, alpha tested particles to depth buffer in the depth prepass as well as draw them first.
		possibly a trace to entity - similar to darkplaces style

	postprocess
		color correction - easy, fairly straightforward
		hdr
		bloom - easy, done it before
		ssao - mostly easy, mostly done it before
		DOF - easy, done it before
		lens flare - easy, done it before
		possibly defferred lighting
		option for FXAA as AA method for crappy cards - easy, done it before


	render pipeline
		render sun shadow
		move shadows if needed to be moved. set toupdate to true if they are moved
		if camera is not in env map culling distance for entities, dont re-render it
		if env map is outside of viewport, dont render it

		render env maps, maybe include shadow shading and other env maps (eg, if the order is right, you can have multiple "bounces")
		render reflections with shadows and env maps
		render screenspace color
		postprocess
		flip
		DOO IT AGAIN

		postprocess
			ssao
			fxaa it up
			dof
			bloom
			lens flare


		"color" render
			clear depth buffer and whatnot
			set up matricies
			cull out any entities that are outside viewport
			cull out any grid sections that are outside viewport
			cull out any alpha tested surfaces that are outside viewport
			render depth only of world
			render depth only of entities (maybe only close ones)
			set texturing on
			most likely render alpha tested surfaces with texture mapping (may need to sort alpha tested surfaces by texture before this) (also maybe only close ones)
			render entities. Sort by texture maybe.
			render world, fully textured
			render the faces of skybox that are visible (overdraw already depth tested out) figure out how to set the stencil so that the defferred lighting wont try to shade it
			if deferred lighting, do the lighting pass at this point
			sort alpha blended particles and surfaces and then particle systems. Use a form of sort that itterates and refines upon itself over the course of a few frames.
			render alpha blended particles and surfaces with a small bit of forward lighting and shading.

		mirrors render
			MAYBE if DOF or ssao draw the mirror depth buffer into the screen depth buffer. dont depth test this part, as there might be some geometry behind the mirror
			if not apply dof and ssao when actually drawing the mirror color buffer, and then not apply ssao to mirrors, and trick the DOF into thinking that mirrors are fully in focus
			dont apply fxaa to mirror render
		

		sun shadowmap render
			idk how to do PSSM yet

		light shadowmap render
			get list of entities that are within bounds;
			check if needsUpdate flag is true;
			if list of entities has entities OR needsUpdate is true... if false just continue
			set up the proper matricies
			render world, culling out any grids further than the bounding spehere (likely only need to check the 4 nearest)
			render list of entities

			OPTIONAL may do
			have it render the world when it gets "spawned in"
			when it needs updating, copy that already rendered depth buffer, then render entities onto it
			no need to render world
			may or may not be faster.

			Another optional may do
			write only the static mesh that is within the bounding sphere into a buffer. Now it only has to render that smaller bit of mesh into the shadowmap

physics
	bullet, newton, or ODE.
	in that order.
	bullet, being c++, may be hard to get working, but there is a WIP c wrapper for it.
	server side for most physics , may later move some to clientside.
gamecode/entity management -- mostly done
	quake-style gamecode
	crysis-style "ids" of entities - makes so no collisions can occour, while keeping things allocated
	nextthink - timer
	think - function pointer to do at time of timer
	attachment system
networking
	client-server model for all gamecode
	both client and server will have to do work like matrix math, so if it is single player (eg, localhost) probably use the same matricies for both
	NOT peer to peer, although that would be awesome
	most likely udp. TCP adds too much overhead... maybe tcp for just "status" messages, ie ones that arent going to be corrected in the next 10nth of a second.
	some sort of delta encoding for speed.
	probably some method of not updating entities as much if you aren't looking at them. Like 10* a second verses 50*
sound
	openAL
	not too much thought to put into it... it's openAL
	loudest/distance get top priority.
world
	Split up into grid sections. Each grid keeps track of its objects, bounding box size, VAO, etc.
	when "baking", order models by texture, apply matrix transformations, add with vertex offsets to VBOs.
	could "bake" in shader using transform feedback, likely wont
	When editing, it adds "fake" entities to the grid these can be moved around and etc. Selecting an object that is already "baked" will remove it from the baked VBO and transfer it into fake entity.
	I dont know if i will have support for transparent objects or if that will be a seperate path.





order of me doing things (not in explicit order)

	finish model loading, animation and
	finish major rendering subsystems

	finish world loading and editing
	finish input systems
	get some sort of basic gamecode and entity management -- mostly done actually
	basic networking
	finish particle system
	basic physics
	sound
	more advanced physics
	more advanced rendering (shadows, env maps, etc)
	more advanced networking (client side physics processing, client side hit detection, client side interpolation, server update queing)














misc notes

Shader permutations has to take into account things with only diffuse maps or etc.
	That way i can bound all diffuse maps into 0, all normals into 1, all spec into 2, etc.
	But, if a model only has a diffuse and a normal, it wont try to shade its normals with the previous model's specular maps
